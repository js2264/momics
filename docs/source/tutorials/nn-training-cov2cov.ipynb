{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train neural networks with `momics` and `tensorflow`\n",
    "\n",
    "`momics` provides several useful resources to train neural networks with `tensorflow`. This notebook demonstrates how to train a simple neural network with `momics` and `tensorflow`.\n",
    "\n",
    "## Connect to the data repository\n",
    "\n",
    "We will tap into the repository generated in the [previous tutorial](integrating-multiomics.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "momics :: INFO :: 2025-03-29 23:27:16,813 :: No cloud config found for momics.Consider populating `~/.momics.ini` file with configuration settings for cloud access.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>atac</td>\n",
       "      <td>/home/jaseriza/repos/momics/data/S288c_atac.bw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>scc1</td>\n",
       "      <td>/home/jaseriza/repos/momics/data/S288c_scc1.bw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mnase</td>\n",
       "      <td>/home/jaseriza/repos/momics/data/S288c_mnase.bw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  label                                             path\n",
       "0    0   atac   /home/jaseriza/repos/momics/data/S288c_atac.bw\n",
       "1    1   scc1   /home/jaseriza/repos/momics/data/S288c_scc1.bw\n",
       "2    2  mnase  /home/jaseriza/repos/momics/data/S288c_mnase.bw"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from momics import momics as mmm\n",
    "\n",
    "## Creating repository\n",
    "repo = mmm.Momics(\"yeast_CNN_data.momics\")\n",
    "\n",
    "## Check that sequence and some tracks are registered\n",
    "repo.seq()\n",
    "repo.tracks()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify some tracks\n",
    "\n",
    "We can first pre-process the tracks to normalize them, and save them back to the local repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "momics :: INFO :: 2025-03-29 23:27:21,396 :: 1 tracks ingested in 1.4004s.\n",
      "momics :: INFO :: 2025-03-29 23:27:26,492 :: 1 tracks ingested in 1.6719s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>atac</td>\n",
       "      <td>/home/jaseriza/repos/momics/data/S288c_atac.bw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>scc1</td>\n",
       "      <td>/home/jaseriza/repos/momics/data/S288c_scc1.bw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mnase</td>\n",
       "      <td>/home/jaseriza/repos/momics/data/S288c_mnase.bw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>atac_rescaled</td>\n",
       "      <td>tmpbyibsue1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mnase_rescaled</td>\n",
       "      <td>tmpoqeo1dwd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx           label                                             path\n",
       "0    0            atac   /home/jaseriza/repos/momics/data/S288c_atac.bw\n",
       "1    1            scc1   /home/jaseriza/repos/momics/data/S288c_scc1.bw\n",
       "2    2           mnase  /home/jaseriza/repos/momics/data/S288c_mnase.bw\n",
       "3    3   atac_rescaled                                      tmpbyibsue1\n",
       "4    4  mnase_rescaled                                      tmpoqeo1dwd"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for track in [\"atac\", \"mnase\"]:\n",
    "    cov = repo.tracks(track)\n",
    "    # Compute genome-wide 99th percentile\n",
    "    q99 = np.nanpercentile(np.concatenate(list(cov.values())), 99)\n",
    "    for chrom in cov.keys():\n",
    "        arr = cov[chrom]\n",
    "        # Truncate to genome-wide 99th percentile\n",
    "        arr = np.minimum(arr, q99)\n",
    "        # Rescale to [0, 1]\n",
    "        arr = (arr - np.nanmin(arr)) / (np.nanmax(arr) - np.nanmin(arr))\n",
    "        # Convert NaNs to 0\n",
    "        arr = np.nan_to_num(arr, nan=0)\n",
    "        # Store back\n",
    "        cov[chrom] = arr\n",
    "    repo.ingest_track(cov, track + \"_rescaled\")\n",
    "\n",
    "repo.tracks()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define datasets and model \n",
    "\n",
    "We will define a simple convolutional neural network with `tensorflow` to predict the target variable `ATAC` from the feature variable `MNase`. This requires to first define a set of genomic coordinates to extract genomic data from. We will use `MNase_rescaled` coverage scores over tiling genomic windows (`features_size` of `1025`, with a stride of `48`) as feature variables to predict `ATAC_rescaled` coverage scores over the same tiling genomic windows, but narrowed down to the a `target_size` of `24` bp around the center of the window. We can split the data into training, testing and validation sets, using `momics.utils.split_ranges()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>137472</td>\n",
       "      <td>145665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>59392</td>\n",
       "      <td>67585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>137216</td>\n",
       "      <td>145409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>32512</td>\n",
       "      <td>40705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>30720</td>\n",
       "      <td>38913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27695</th>\n",
       "      <td>XV</td>\n",
       "      <td>1025024</td>\n",
       "      <td>1033217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27696</th>\n",
       "      <td>XV</td>\n",
       "      <td>773120</td>\n",
       "      <td>781313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27697</th>\n",
       "      <td>XV</td>\n",
       "      <td>533248</td>\n",
       "      <td>541441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27698</th>\n",
       "      <td>XV</td>\n",
       "      <td>416768</td>\n",
       "      <td>424961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27699</th>\n",
       "      <td>XV</td>\n",
       "      <td>108800</td>\n",
       "      <td>116993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27700 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "+--------------+-----------+-----------+\n",
       "| Chromosome   | Start     | End       |\n",
       "| (category)   | (int64)   | (int64)   |\n",
       "|--------------+-----------+-----------|\n",
       "| I            | 137472    | 145665    |\n",
       "| I            | 59392     | 67585     |\n",
       "| I            | 137216    | 145409    |\n",
       "| I            | 32512     | 40705     |\n",
       "| ...          | ...       | ...       |\n",
       "| XV           | 773120    | 781313    |\n",
       "| XV           | 533248    | 541441    |\n",
       "| XV           | 416768    | 424961    |\n",
       "| XV           | 108800    | 116993    |\n",
       "+--------------+-----------+-----------+\n",
       "Unstranded PyRanges object has 27,700 rows and 3 columns from 16 chromosomes.\n",
       "For printing, the PyRanges was sorted on Chromosome."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import momics.utils as mutils\n",
    "\n",
    "# Fetch data from the momics repository\n",
    "features_size = 8192 + 1\n",
    "stride = 256\n",
    "\n",
    "bins = repo.bins(width=features_size, stride=stride, cut_last_bin_out=True)\n",
    "bins = bins.subset(lambda x: x.Chromosome != \"XVI\")\n",
    "bins_split, bins_test = mutils.split_ranges(bins, 0.8)\n",
    "bins_train, bins_val = mutils.split_ranges(bins_split, 0.8)\n",
    "bins_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to define different datasets, for training, testing and validation. We will use `momics.dataset.MomicsDataset()` constructor, indicating the batch size we wish to use in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:27:26.792513: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-29 23:27:26.801110: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743287246.811634 3927205 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743287246.814957 3927205 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-29 23:27:26.826531: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1743287248.074337 3927205 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10368 MB memory:  -> device: 0, name: NVIDIA RTX A2000 12GB, pci bus id: 0000:55:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_RepeatDataset element_spec=((TensorSpec(shape=(None, 8193, 1), dtype=tf.float32, name=None),), (TensorSpec(shape=(None, 512, 1), dtype=tf.float32, name=None),))>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from momics.dataset import MomicsDataset\n",
    "\n",
    "features = \"mnase_rescaled\"\n",
    "target = \"atac_rescaled\"\n",
    "target_size = 512\n",
    "batch_size = 500\n",
    "\n",
    "train_dataset = (\n",
    "    MomicsDataset(repo, bins_train, features, target, target_size=target_size, batch_size=batch_size)\n",
    "    .shuffle(10)\n",
    "    .prefetch(2)\n",
    "    .repeat()\n",
    ")\n",
    "val_dataset = MomicsDataset(repo, bins_val, features, target, target_size=target_size, batch_size=batch_size)\n",
    "test_dataset = MomicsDataset(repo, bins_test, features, target, target_size=target_size, batch_size=batch_size)\n",
    "train_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is time to define the model architecture. In this example, we will use a simple customizable convolutional neural network (`ChromNN`), provided in `momics.nn`. We can instantiate the model with the number and shape of layers we want, and compile it with the desired optimizer, loss function and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8193</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8193</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4097</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4097</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4097</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4097</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2049</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2049</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2049</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2049</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1025</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1025</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8200</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,198,912</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8193\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8193\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4097\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4097\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4097\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4097\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │         \u001b[38;5;34m8,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2049\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2049\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2049\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2049\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │        \u001b[38;5;34m10,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1025\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1025\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8200\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m4,198,912\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,217,976</span> (16.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,217,976\u001b[0m (16.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,217,800</span> (16.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,217,800\u001b[0m (16.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> (704.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m176\u001b[0m (704.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from momics.nn import ChromNN\n",
    "from momics.nn import mae_cor\n",
    "import tensorflow as tf  # type: ignore\n",
    "from tensorflow.keras import layers  # type: ignore\n",
    "\n",
    "## Define the model with three convolutional layers\n",
    "model = ChromNN(\n",
    "    input=layers.Input(shape=(features_size, 1)),\n",
    "    output=layers.Dense(target_size, activation=\"linear\"),\n",
    "    filters=[64, 16, 8],\n",
    "    kernel_sizes=[3, 8, 80],\n",
    ").model\n",
    "\n",
    "\n",
    "## Use a combination of MAE and correlation as loss function\n",
    "def loss_fn(y_true, y_pred):\n",
    "    return mae_cor(y_true, y_pred, alpha=0.9)\n",
    "\n",
    "\n",
    "## Use Adam optimizer, a learning rate of 0.001, and return MAE as metric\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=loss_fn,\n",
    "    metrics=[\"mae\"],\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the datasets and the model, we can fit the model to the training data, using the `fit()` method of the model. We can also evaluate the model on the testing and validation datasets. Here, we'll quickly iterate over 10 epochs, but you can increase this number to improve the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaseriza/micromamba/envs/momics/lib/python3.10/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor_1\n",
      "Received: inputs=('Tensor(shape=(None, 8193, 1))',)\n",
      "  warnings.warn(msg)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743287250.405082 3927603 service.cc:148] XLA service 0x7f88fc021190 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743287250.405103 3927603 service.cc:156]   StreamExecutor device (0): NVIDIA RTX A2000 12GB, Compute Capability 8.6\n",
      "2025-03-29 23:27:30.456058: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743287250.689129 3927603 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-03-29 23:27:41.060101: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng1{k2=2,k3=0} for conv (f32[1,64,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,500,1,8193]{3,2,1,0}, f32[64,500,1,8193]{3,2,1,0}), window={size=1x8193 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-03-29 23:27:41.651592: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.591598431s\n",
      "Trying algorithm eng1{k2=2,k3=0} for conv (f32[1,64,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,500,1,8193]{3,2,1,0}, f32[64,500,1,8193]{3,2,1,0}), window={size=1x8193 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "I0000 00:00:1743287266.478668 3927603 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - loss: 0.6103 - mae: 0.5706"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaseriza/micromamba/envs/momics/lib/python3.10/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor_1\n",
      "Received: inputs=('Tensor(shape=(None, 8193, 1))',)\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 440ms/step - loss: 0.6075 - mae: 0.5676 - val_loss: 0.3204 - val_mae: 0.2526 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 213ms/step - loss: 0.3050 - mae: 0.2399 - val_loss: 0.2367 - val_mae: 0.1671 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 210ms/step - loss: 0.2712 - mae: 0.2081 - val_loss: 0.2435 - val_mae: 0.1761 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 217ms/step - loss: 0.2652 - mae: 0.2046 - val_loss: 0.2286 - val_mae: 0.1616 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 220ms/step - loss: 0.2489 - mae: 0.1882 - val_loss: 0.2290 - val_mae: 0.1656 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 230ms/step - loss: 0.2303 - mae: 0.1699 - val_loss: 0.2189 - val_mae: 0.1582 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 217ms/step - loss: 0.2398 - mae: 0.1801 - val_loss: 0.2058 - val_mae: 0.1437 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 349ms/step - loss: 0.2220 - mae: 0.1618 - val_loss: 0.2029 - val_mae: 0.1380 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 278ms/step - loss: 0.2141 - mae: 0.1546 - val_loss: 0.1977 - val_mae: 0.1349 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 206ms/step - loss: 0.2080 - mae: 0.1487 - val_loss: 0.1985 - val_mae: 0.1351 - learning_rate: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f8b68d669e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau  # type: ignore\n",
    "\n",
    "os.makedirs(\".chromnn\", exist_ok=True)\n",
    "callbacks_list = [\n",
    "    CSVLogger(Path(\".chromnn\", \"epoch_data.csv\")),\n",
    "    ModelCheckpoint(filepath=Path(\".chromnn\", \"Checkpoint.keras\"), monitor=\"val_loss\", save_best_only=True),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=40, min_delta=1e-5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=6 // 2, min_lr=0.1 * 0.001),\n",
    "]\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks_list,\n",
    "    steps_per_epoch=int(np.floor(len(bins_train) // batch_size)),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and save model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the trained model performs, and save it to the local repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - loss: 0.1961 - mae: 0.1326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19540582597255707, 0.13238614797592163]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model with our test dataset\n",
    "model.evaluate(test_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model to predict ATAC-seq coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "momics :: INFO :: 2025-03-29 23:30:34,206 :: Saved coverage for atac to prediction_atac.bw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'atac': {'I': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'II': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'III': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'IV': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'V': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'VI': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'VII': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'VIII': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'IX': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'X': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'XI': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'XII': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'XIII': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'XIV': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'XV': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'XVI': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'Mito': array([0., 0., 0., ..., 0., 0., 0.])}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from momics import dataset as mmd\n",
    "from momics import aggregate as mma\n",
    "\n",
    "## Predict the ATAC signal from the MNase signal\n",
    "bb = repo.bins(width=features_size, stride=8, cut_last_bin_out=True)[\"XVI\"]\n",
    "ds = mmd.MomicsDataset(repo, bb, \"mnase_rescaled\", batch_size=1000).prefetch(10)\n",
    "predictions = model.predict(ds)\n",
    "\n",
    "## Export predictions as a bigwig\n",
    "centered_bb = bb.copy()\n",
    "centered_bb.Start = centered_bb.Start + features_size // 2 - target_size // 2\n",
    "centered_bb.End = centered_bb.Start + target_size\n",
    "chrom_sizes = repo.chroms(as_dict=True)\n",
    "keys = [f\"{chrom}:{start}-{end}\" for chrom, start, end in zip(centered_bb.Chromosome, centered_bb.Start, centered_bb.End)]\n",
    "res = {f\"atac-from-mnase_f{features_size}_s{stride}_t{target_size}\": {k: None for k in keys}}\n",
    "for i, key in enumerate(keys):\n",
    "    res[f\"atac-from-mnase_f{features_size}_s{stride}_t{target_size}\"][key] = predictions[i]\n",
    "\n",
    "mma.aggregate(res, centered_bb, chrom_sizes, type=\"mean\", prefix=\"prediction\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates a new `bw` file with ATAC-seq coverage over chr16, predicted from MNase-seq coverage.\n",
    "\n",
    "Here is a screenshot of ATAC-seq coverage track over chr16, from experimental data (darker cyan) or predicted from MNase-seq coverage (MNase: grey track; predicted ATAC: lighter cyan), taken from IGV:\n",
    "\n",
    "![ATAC-seq coverage track over chr16](images/atac_mnase.png)\n",
    "\n",
    "A closer look: \n",
    "\n",
    "![ATAC-seq coverage track over chr16, zoom](images/atac_mnase2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
